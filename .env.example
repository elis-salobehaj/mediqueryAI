# ==========================================
# MediQuery AI - Master Environment Config
# ==========================================

# --- Backend Configuration ---

# Google Gemini API Key
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_api_key_here

# Anthropic API Key
# Get your API key from: https://console.anthropic.com/api
ANTHROPIC_API_KEY=your_api_key_here

# Local Model Configuration (Ollama)
USE_LOCAL_MODEL=true                      # true = local, false = cloud
LOCAL_MODEL_NAME=qwen2.5-coder:7b         # Options: qwen2.5-coder:7b, sqlcoder:7b, llama3.1, qwen3:latest
OLLAMA_HOST=http://localhost:11434

# Multi-Agent Model Configuration (for LangGraph workflow)
SCHEMA_NAVIGATOR_MODEL=qwen2.5-coder:7b   # Schema analysis agent
SQL_WRITER_MODEL=sqlcoder:7b              # SQL generation agent
CRITIC_MODEL=llama3.1                     # SQL validation/critique agent

# --- AWS Bedrock Configuration ---
# Enable Bedrock as LLM provider (alternative to Ollama)
USE_BEDROCK=false
AWS_BEDROCK_REGION=us-west-2
AWS_BEARER_TOKEN_BEDROCK=your_bedrock_api_key_here

# Bedrock Model Configuration (Claude 3.5 family - on-demand)
# Claude 3.5 Sonnet v2: Best for complex SQL generation (~$3/M input tokens)
# Claude 3.5 Haiku: Fast for schema navigation and validation (~$0.80/M input tokens)
BEDROCK_SQL_WRITER_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0
BEDROCK_NAVIGATOR_MODEL=anthropic.claude-3-5-haiku-20241022-v1:0
BEDROCK_CRITIC_MODEL=anthropic.claude-3-5-haiku-20241022-v1:0

# Security
JWT_SECRET_KEY=change_this_to_a_secure_random_string

# System Settings
# Chat History Auto-Deletion
# How long to keep chat messages before auto-deletion (in hours)
# Examples: 24 (1 day), 48 (2 days), 168 (1 week), 720 (30 days)
CHAT_HISTORY_RETENTION_HOURS=24

# DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=DEBUG

# --- Frontend Configuration ---

# API URL (Used by Vite)
# Local: http://localhost:8000
# Docker: http://backend:8000
VITE_API_URL=http://localhost:8000