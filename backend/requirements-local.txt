# Local model configuration (includes heavy ML libraries)
-r requirements-base.txt

# Local model providers
ollama>=0.3.0
langchain-ollama>=0.1.0

# Google Gemini support
google-genai>=0.7.0
google-api-core>=2.19.0
langchain-google-genai>=2.0.0

# LlamaIndex for semantic search (heavy dependencies)
llama-index>=0.11.0
llama-index-llms-ollama>=0.3.0
llama-index-embeddings-huggingface>=0.3.0
